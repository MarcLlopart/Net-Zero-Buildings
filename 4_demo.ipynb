{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All objects loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# File paths (assuming these are correct as provided)\n",
    "filepaths = {\n",
    "    \"encoders\": \"models/label_encoders.pkl\",\n",
    "    \"scaler\": \"models/scaler.pkl\",\n",
    "    \"linear_regression\": \"models/linear_model.pkl\",\n",
    "    \"xgb_model\": \"models/xgb_model.pkl\",\n",
    "    \"data\": \"models/dataframe.pkl\",\n",
    "    \"neural_network\": \"models/nn_model.pth\" \n",
    "}\n",
    "\n",
    "# Load all necessary objects\n",
    "with open(filepaths[\"encoders\"], \"rb\") as f:\n",
    "    encoders = pickle.load(f)\n",
    "\n",
    "with open(filepaths[\"scaler\"], \"rb\") as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "with open(filepaths[\"linear_regression\"], \"rb\") as f:\n",
    "    lr_model = pickle.load(f)\n",
    "\n",
    "with open(filepaths[\"xgb_model\"], \"rb\") as f:\n",
    "    xgb_model = pickle.load(f)\n",
    "\n",
    "with open(filepaths[\"data\"], \"rb\") as f:\n",
    "    full_dataset = pickle.load(f)\n",
    "\n",
    "print(\"\\n✅ All objects loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Models refitted with full dataset!\n"
     ]
    }
   ],
   "source": [
    "selected_cols = [\n",
    "    \"METRES_CADASTRE\", \"Energia primària no renovable\", \"Emissions de CO2\",\n",
    "    \"Energia calefacció\", \"Energia refrigeració\", \"Energia calefacció demanda\", \"VALOR AILLAMENTS\",\n",
    "    \"Cost anual aproximat d'energia per habitatge\", \"VALOR FINESTRES\",\n",
    "    \"POBLACIO\",  \"Qualificació de consum d'energia primaria no renovable\",\n",
    "    \"VEHICLE ELECTRIC\", \"SISTEMA BIOMASSA\", \"REHABILITACIO_ENERGETICA\", \n",
    "    \"Consum d'energia final\"\n",
    "    ]\n",
    "\n",
    "numeric_features = [\n",
    "    \"METRES_CADASTRE\", \"Energia primària no renovable\", \"Emissions de CO2\",\n",
    "    \"Energia calefacció\", \"Energia refrigeració\", \"Energia calefacció demanda\", \"VALOR AILLAMENTS\",\n",
    "    \"Cost anual aproximat d'energia per habitatge\", \"VALOR FINESTRES\"\n",
    "    ]\n",
    "\n",
    "target = \"Consum d'energia final\"\n",
    "\n",
    "X_full = full_dataset[selected_cols].drop(target, axis=1)\n",
    "y_full = full_dataset[target]\n",
    "\n",
    "lr_model.fit(X_full, y_full)\n",
    "xgb_model.fit(X_full, y_full)\n",
    "print(\"\\n✅ Models refitted with full dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xz/5bn1vdj146n6586g9r465k_40000gn/T/ipykernel_96647/3719673932.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  nn_model.load_state_dict(torch.load(filepaths[\"neural_network\"]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EnergyNN(\n",
       "  (fc1): Linear(in_features=14, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (output): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EnergyNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(EnergyNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.output = nn.Linear(32, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "nn_model = EnergyNN(X_full.shape[1])  # Initialize with input dimension from full dataset\n",
    "nn_model.load_state_dict(torch.load(filepaths[\"neural_network\"]))\n",
    "nn_model.eval()  # Set to evaluation mode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input\n",
    "example_input = {\n",
    "    'METRES_CADASTRE': 383, \n",
    "    'Energia primària no renovable': 308.355, \n",
    "    'Emissions de CO2': 40,\n",
    "    'Energia calefacció': 5.25,\n",
    "    'Energia refrigeració': 0,\n",
    "    'Energia calefacció demanda': 5.25,\n",
    "    'VALOR AILLAMENTS': 2.5,\n",
    "    \"Cost anual aproximat d'energia per habitatge\": 2600,\n",
    "    'VALOR FINESTRES': 3.0,\n",
    "    'POBLACIO': 'Gelida',  \n",
    "    \"Qualificació de consum d'energia primaria no renovable\": 'D',\n",
    "    'VEHICLE ELECTRIC': '0', \n",
    "    'SISTEMA BIOMASSA': '0', \n",
    "    'REHABILITACIO_ENERGETICA': '0'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(input_dict, encoders, scaler, reference_df):\n",
    "    # Convert input to DataFrame\n",
    "    input_df = pd.DataFrame([input_dict])\n",
    "    \n",
    "    # Separate numerical and categorical columns based on reference dataset\n",
    "    numeric_features = [\n",
    "    \"METRES_CADASTRE\", \"Energia primària no renovable\", \"Emissions de CO2\",\n",
    "    \"Energia calefacció\", \"Energia refrigeració\", \"Energia calefacció demanda\", \"VALOR AILLAMENTS\",\n",
    "    \"Cost anual aproximat d'energia per habitatge\", \"VALOR FINESTRES\"\n",
    "    ]\n",
    "\n",
    "# Categorical features (to encode)\n",
    "    categorical_features = [\n",
    "        \"POBLACIO\",  \"Qualificació de consum d'energia primaria no renovable\",\n",
    "        \"VEHICLE ELECTRIC\", \"SISTEMA BIOMASSA\", \"REHABILITACIO_ENERGETICA\"\n",
    "        ]     \n",
    "    # Handle categorical variables\n",
    "    for col in categorical_features:\n",
    "        if col in input_df.columns:\n",
    "            if col in encoders:\n",
    "                try:\n",
    "                    input_df[col] = encoders[col].transform(input_df[col])\n",
    "                except ValueError as e:\n",
    "                    print(f\"Warning: Unseen label in {col}. Assigning default value...\")\n",
    "                    # Assign most common value or a neutral value from training data\n",
    "                    default_value = reference_df[col].mode()[0]\n",
    "                    input_df[col] = default_value\n",
    "                    input_df[col] = encoders[col].transform([default_value])[0]\n",
    "    \n",
    "    # Ensure all columns match the training data\n",
    "    input_df[numeric_features] = scaler.transform(input_df[numeric_features])\n",
    "    \n",
    "    # Scale numerical features\n",
    "    input_scaled = input_df\n",
    "    input_tensor = torch.tensor(input_scaled.values, dtype=torch.float32)\n",
    "    \n",
    "    return input_scaled, input_tensor\n",
    "\n",
    "\n",
    "# Preprocess the input\n",
    "processed_input, input_tensor = preprocess_input(example_input, encoders, scaler, X_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions:\n",
      "Linear Regression Prediction: 1.99 kWh/m²\n",
      "XGBoost Prediction: 7.12 kWh/m²\n",
      "Neural Network Prediction: 179.29 kWh/m²\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "lr_prediction = lr_model.predict(processed_input)\n",
    "xgb_prediction = xgb_model.predict(processed_input)\n",
    "with torch.no_grad():  # No gradient computation for inference\n",
    "    nn_prediction = nn_model(input_tensor).item()  # Get scalar value from tensor\n",
    "\n",
    "# Output results\n",
    "print(\"\\nPredictions:\")\n",
    "print(f\"Linear Regression Prediction: {lr_prediction[0]:.2f} kWh/m²\")\n",
    "print(f\"XGBoost Prediction: {xgb_prediction[0]:.2f} kWh/m²\")\n",
    "print(f\"Neural Network Prediction: {nn_prediction:.2f} kWh/m²\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
