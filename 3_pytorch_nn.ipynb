{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xz/5bn1vdj146n6586g9r465k_40000gn/T/ipykernel_30091/4013270058.py:9: DtypeWarning: Columns (65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('data/EPC_Catalonia.csv')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_csv('data/EPC_Catalonia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xz/5bn1vdj146n6586g9r465k_40000gn/T/ipykernel_30091/1441265325.py:6: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df[\"DATA_ENTRADA\"] = pd.to_datetime(df[\"DATA_ENTRADA\"], errors=\"coerce\")\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()\n",
    "# Define target variable (Energy Consumption)\n",
    "target = \"Consum d'energia final\"\n",
    "\n",
    "# Extract date features\n",
    "df[\"DATA_ENTRADA\"] = pd.to_datetime(df[\"DATA_ENTRADA\"], errors=\"coerce\")\n",
    "df[\"YEAR\"] = df[\"DATA_ENTRADA\"].dt.year\n",
    "df[\"MONTH\"] = df[\"DATA_ENTRADA\"].dt.month\n",
    "\n",
    "# Drop original date column\n",
    "df.drop(columns=[\"DATA_ENTRADA\"], inplace=True)\n",
    "\n",
    "# Numerical features\n",
    "numeric_features = [\n",
    "    \"METRES_CADASTRE\", \"ANY_CONSTRUCCIO\", \"Energia primària no renovable\", \"Emissions de CO2\",\n",
    "    \"Energia calefacció\", \"Energia refrigeració\", \"Energia ACS\", \"Energia enllumenament\",\n",
    "    \"Energia calefacció demanda\", \"Energia refrigeració demanda\", \"VALOR AILLAMENTS\",\n",
    "    \"VALOR FINESTRES\", \"YEAR\", \"MONTH\", \"Cost anual aproximat d'energia per habitatge\"\n",
    "]\n",
    "\n",
    "# Categorical features (to encode)\n",
    "categorical_features = [\n",
    "    \"POBLACIO\", \"COMARCA\", \"NOM_PROVINCIA\", \"CODI_POBLACIO\", \"CODI_COMARCA\", \"CODI_PROVINCIA\",\n",
    "    \"ZONA CLIMATICA\", \"US_EDIFICI\", \"VEHICLE ELECTRIC\", \"SOLAR TERMICA\", \"SOLAR FOTOVOLTAICA\",\n",
    "    \"SISTEMA BIOMASSA\", \"XARXA DISTRICTE\", \"ENERGIA GEOTERMICA\", \"REHABILITACIO_ENERGETICA\",\n",
    "    \"Qualificació de consum d'energia primaria no renovable\", \"Qualificacio d'emissions de CO2\"\n",
    "]\n",
    "\n",
    "# Convert binary categorical features to numeric (Yes/No -> 1/0)\n",
    "binary_features = [\"VEHICLE ELECTRIC\", \"SOLAR TERMICA\", \"SOLAR FOTOVOLTAICA\", \n",
    "                   \"SISTEMA BIOMASSA\", \"XARXA DISTRICTE\", \"ENERGIA GEOTERMICA\", \n",
    "                   \"REHABILITACIO_ENERGETICA\"]\n",
    "\n",
    "for col in binary_features:\n",
    "    df[col] = df[col].str.lower().map({'si': 1, 'no': 0}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for cat in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df[cat] = le.fit_transform(df[cat])\n",
    "    label_encoders[cat] = le  # Save for later\n",
    "df = df[numeric_features + categorical_features + [target]].dropna()\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "df[numeric_features] = scaler.fit_transform(df[numeric_features])\n",
    "\n",
    "X = df.drop(columns=[target]).values\n",
    "y = df[target].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Create dataset\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# Split into train and test (80-20)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/200], Loss: 13549.2870\n",
      "Epoch [10/200], Loss: 11172.6763\n",
      "Epoch [20/200], Loss: 13958.7698\n",
      "Epoch [30/200], Loss: 9758.9553\n",
      "Epoch [40/200], Loss: 10449.9565\n",
      "Epoch [50/200], Loss: 8091.6381\n",
      "Epoch [60/200], Loss: 8764.5358\n",
      "Epoch [70/200], Loss: 5834.7030\n",
      "Epoch [80/200], Loss: 5567.7651\n",
      "Epoch [90/200], Loss: 6224.0936\n",
      "Epoch [100/200], Loss: 5620.0012\n",
      "Epoch [110/200], Loss: 4551.8710\n",
      "Epoch [120/200], Loss: 6315.9488\n",
      "Epoch [130/200], Loss: 5243.3092\n",
      "Epoch [140/200], Loss: 7805.0443\n",
      "Epoch [150/200], Loss: 4805.5783\n",
      "Epoch [160/200], Loss: 6461.4075\n",
      "Epoch [170/200], Loss: 13927.9698\n",
      "Epoch [180/200], Loss: 4758.1559\n",
      "Epoch [190/200], Loss: 4624.1373\n"
     ]
    }
   ],
   "source": [
    "class EnergyNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(EnergyNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.output = nn.Linear(32, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "input_dim = X.shape[1]\n",
    "model = EnergyNN(input_dim)\n",
    "\n",
    "# Define loss & optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# -------------- TRAINING LOOP --------------\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# -------------- EVALUATION --------------\n",
    "model.eval()\n",
    "predictions = []\n",
    "actuals = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        preds = model(X_batch)\n",
    "        predictions.append(preds.numpy())\n",
    "        actuals.append(y_batch.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network Metrics:\n",
      "MAE: 36.65\n",
      "RMSE: 48.18\n",
      "R² Score: 0.65\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions = np.vstack(predictions)\n",
    "actuals = np.vstack(actuals)\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "print(f\"\\nNeural Network Metrics:\")\n",
    "print(f\"MAE: {mean_absolute_error(actuals, predictions):.2f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(actuals, predictions)):.2f}\")\n",
    "print(f\"R² Score: {r2_score(actuals, predictions):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
